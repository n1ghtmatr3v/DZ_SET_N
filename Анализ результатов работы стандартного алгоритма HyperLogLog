На этом этапе я сравнил практические результаты HyperLogLog с теорией. Точность тут в основном задаётся числом регистров m = 2^B: чем больше m, тем меньше относительная ошибка, но тем больше памяти нужно под регистры. В качестве теоретических ориентиров для относительной ошибки я использовал 1.04/sqrt(m) и более широкую проверку 1.3/sqrt(m). По данным из stats.csv видно, что разброс оценок между разными потоками в целом находится на ожидаемом уровне и по порядку укладывается в эти границы, то есть реализация ведёт себя нормально. По стабильности (или же дисперсии) заметно, что в абсолютных числах отклонения растут вместе с размером потока, но если смотреть относительные величины, то они остаются примерно на одном уровне, без резких провалов — оценка стабильная. По константам и параметрам главное влияние даёт B: увеличение B уменьшает ошибку примерно как 1/sqrt(m), но увеличивает память, поэтому B выбирается как компромисс между точностью и расходом памяти. Шаг, с которым я снимал точки по потоку, влияет только на гладкость графиков и удобство анализа, а не на саму точность алгоритма.
